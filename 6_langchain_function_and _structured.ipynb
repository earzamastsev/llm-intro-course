{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Langchain: function calling and structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Structured Output with langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/langchain_structured_output.png\" width=800px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user='Семен Васильевич' email='semen@mail'\n"
     ]
    }
   ],
   "source": [
    "# Define schema\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "class ResponseFormatter(BaseModel):\n",
    "    \"\"\"Always use this tool to structure your response to the user.\"\"\"\n",
    "    user: str = Field(description=\"User name\")\n",
    "    email: str = Field(description=\"User email\")\n",
    "\n",
    "\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(ResponseFormatter)\n",
    "\n",
    "# Invoke the model to produce structured output that matches the schema\n",
    "structured_output = model_with_structure.invoke('Семен васильевич зарегистрирвал адрес semen@mail')\n",
    "print(structured_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_cuIVSHW7af8HymeoNput9tl9', 'function': {'arguments': '{\"user\":\"Семен Васильевич\",\"email\":\"semen@mail\"}', 'name': 'ResponseFormatter'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 71, 'total_tokens': 95, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-8605c2cb-560c-41c3-98ca-089da85ee3ca-0' tool_calls=[{'name': 'ResponseFormatter', 'args': {'user': 'Семен Васильевич', 'email': 'semen@mail'}, 'id': 'call_cuIVSHW7af8HymeoNput9tl9', 'type': 'tool_call'}] usage_metadata={'input_tokens': 71, 'output_tokens': 24, 'total_tokens': 95, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# use function calling\n",
    "\n",
    "model_with_tools = model.bind_tools([ResponseFormatter])\n",
    "structured_output = model_with_tools.invoke('Семен васильевич зарегистрирвал адрес semen@mail')\n",
    "print(structured_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"имя\": \"Семен Васильевич\",\n",
      "    \"email\": \"semen@mail\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# use json_mode\n",
    "\n",
    "model_json = ChatOpenAI(model=\"gpt-4o\", model_kwargs={ \"response_format\": { \"type\": \"json_object\" } })\n",
    "structured_output = model_json.invoke('Семен васильевич зарегистрирвал адрес semen@mail. Выдели имя и емейл. Ответь ввиде JSON')\n",
    "print(structured_output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "## 2. Tools and Function calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/langchain_function_calling.png\" width=900px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лучшие практики\n",
    "\n",
    "При разработке инструментов, которые будут использоваться моделями, учитывайте следующее:\n",
    "\n",
    "- Инструменты с хорошо подобранными названиями, корректной документацией и правильной типизацией легче использовать моделям.\n",
    "- Разрабатывайте простые и узкоспециализированные инструменты, так как их проще использовать корректно.\n",
    "- Используйте чат-модели, которые поддерживают API для вызова инструментов, чтобы максимально эффективно использовать инструменты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiply two numbers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n",
      "{'description': 'Multiply two numbers.',\n",
      " 'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
      "                'b': {'title': 'B', 'type': 'integer'}},\n",
      " 'required': ['a', 'b'],\n",
      " 'title': 'multiply',\n",
      " 'type': 'object'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ck/mnjcv5_14nq5jzl5wb8kd5gh0000gn/T/ipykernel_37005/1104359578.py:14: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  pp(multiply.args_schema.schema())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from pprint import pp\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "   \"\"\"Multiply two numbers.\"\"\"\n",
    "   return a * b\n",
    "\n",
    "# Let's inspect some of the attributes associated with the tool.\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)\n",
    "\n",
    "pp(multiply.args_schema.schema())\n",
    "\n",
    "multiply.invoke({'a':4, 'b':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Негативный.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tools from chain\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"human\", \"Классифицируй запрос на один из типов: нейтральный, негативный, позитивный. Запрос: {request}.\")]\n",
    ")\n",
    "\n",
    "# Placeholder LLM\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "as_tool = chain.as_tool(\n",
    "    name=\"Feedback classifier\", description=\"Classify user responces.\"\n",
    ")\n",
    "as_tool.args_schema.model_json_schema()\n",
    "\n",
    "as_tool.invoke({'request': 'Отвратительный товар. НИкогда не куплю.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tool = model.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "messages = [HumanMessage(content='Сколько будет 3 умножить на 6?')]\n",
    "response = model_with_tool.invoke(messages)\n",
    "messages.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 6},\n",
       "  'id': 'call_DtKCBtoi8QKjUX3LsEOYLJby',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Сколько будет 3 умножить на 6?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_DtKCBtoi8QKjUX3LsEOYLJby', 'function': {'arguments': '{\"a\":3,\"b\":6}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 56, 'total_tokens': 73, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-586215a6-3196-42b7-9d14-2a6e68161c0e-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 6}, 'id': 'call_DtKCBtoi8QKjUX3LsEOYLJby', 'type': 'tool_call'}], usage_metadata={'input_tokens': 56, 'output_tokens': 17, 'total_tokens': 73, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='18', name='multiply', tool_call_id='call_DtKCBtoi8QKjUX3LsEOYLJby')]\n"
     ]
    }
   ],
   "source": [
    "for tool_call in response.tool_calls:\n",
    "    selected_tool = { \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='3 умножить на 6 будет 18.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 81, 'total_tokens': 93, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None}, id='run-f4d6fdb6-7984-47cb-9f7c-ab43ab857da8-0', usage_metadata={'input_tokens': 81, 'output_tokens': 12, 'total_tokens': 93, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tool.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
