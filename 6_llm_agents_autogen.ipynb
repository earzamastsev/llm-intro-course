{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/autogen_conv.png\" width=600px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install autogen-agentchat~=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pp\n",
    "import dotenv\n",
    "from autogen import ConversableAgent\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    \"chatbot\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "reply = agent.generate_reply(messages=[{\"content\": \"Ты кто? Представься и скажи кто тебя создал\", \"role\": \"user\"}])\n",
    "pp(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/autogen_main.png\" width=600px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automechanic = ConversableAgent(\n",
    "    \"automechanic\",\n",
    "    system_message='Ты - Семеныч, ты автомеханик с 10 летним опытом. Ты отлично разбираешься в моторах и автомобилях. У тебя нет высшего образования, ты все освоил сам на собственном опыте.',\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "customer = ConversableAgent(\n",
    "    \"customer\",\n",
    "    system_message='Ты - автолюбитель, приехал в автосервис для ремонта автомобиля. Ты ничего не понимаешь в автомобилях и их принципе работы.',\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "result = customer.initiate_chat(automechanic, message=\"Добрый день. Подскажите, у меня чтото стучит под капотом. Можете помочь с ремонтом?.\", max_turns=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Termination conversaton\n",
    "\n",
    "- Укажите параметры в initiate_chat: При инициировании чата вы можете задать параметры, которые определяют, когда разговор должен завершиться.\n",
    "\n",
    "- Настройка агента для вызова завершения: При определении отдельных агентов вы можете задать параметры, которые позволяют агентам завершать разговор на основе определенных (конфигурируемых) условий.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automechanic = ConversableAgent(\n",
    "    \"automechanic\",\n",
    "    system_message='Ты - Семеныч, ты автомеханик с 10 летним опытом. Ты отлично разбираешься в моторах и автомобилях. Вначале ты задаешь все уточняюшие вопрсоы, если нет вомзожности решить проблему сходу - ты предлагаешь потом предлагаешь записаться на диагностику.',\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    is_termination_msg=lambda msg: 'записаться' in msg[\"content\"].lower()\n",
    ")\n",
    "\n",
    "customer = ConversableAgent(\n",
    "    \"customer\",\n",
    "    system_message='Ты - автолюбитель, приехал в автосервис для ремонта автомобиля. Ты ничего не понимаешь в автомобилях и их принципе работы.',\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "result = customer.initiate_chat(automechanic, message=\"Добрый день. Подскажите, у меня чтото стучит под капотом. Можете помочь с ремонтом?.\", max_turns=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human-in-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automechanic = ConversableAgent(\n",
    "    \"automechanic\",\n",
    "    system_message='Ты - Семеныч, ты автомеханик с 10 летним опытом. Ты отлично разбираешься в моторах и автомобилях. Вначале ты задаешь все уточняюшие вопрсоы, если нет вомзожности решить проблему сходу - ты предлагаешь потом предлагаешь записаться на диагностику.',\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    is_termination_msg=lambda msg: 'записаться' in msg[\"content\"].lower()\n",
    ")\n",
    "\n",
    "customer = ConversableAgent(\n",
    "    \"customer\",\n",
    "    system_message='Ты - автолюбитель, приехал в автосервис для ремонта автомобиля. Ты ничего не понимаешь в автомобилях и их принципе работы.',\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"ALWAYS\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "result = customer.initiate_chat(automechanic, message=\"Добрый день. Подскажите, у меня чтото стучит под капотом. Можете помочь с ремонтом?.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automechanic = ConversableAgent(\n",
    "    \"automechanic\",\n",
    "    system_message='Ты - Семеныч, ты автомеханик с 10 летним опытом. Ты отлично разбираешься в моторах и автомобилях. Вначале ты задаешь все уточняюшие вопрсоы, если нет вомзожности решить проблему сходу - ты предлагаешь потом предлагаешь записаться на диагностику.',\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    is_termination_msg=lambda msg: 'записаться' in msg[\"content\"].lower()\n",
    ")\n",
    "\n",
    "customer = ConversableAgent(\n",
    "    \"customer\",\n",
    "    system_message='Ты - автолюбитель, приехал в автосервис для ремонта автомобиля. Ты ничего не понимаешь в автомобилях и их принципе работы.',\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"ALWAYS\",  # Never ask for human input.\n",
    "    \n",
    ")\n",
    "\n",
    "result = customer.initiate_chat(automechanic, \n",
    "                                message=\"Добрый день. Подскажите, у меня чтото стучит под капотом. Можете помочь с ремонтом?.\", \n",
    "                                max_turn=2,\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Сode executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/autogen_code.png\" width=600px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "\n",
    "# Create a temporary directory to store the code files.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Create a local command line code executor.\n",
    "executor = LocalCommandLineCodeExecutor(\n",
    "    timeout=10,  # Timeout for each code execution in seconds.\n",
    "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
    ")\n",
    "\n",
    "# Create an agent with code executor configuration.\n",
    "code_executor_agent = ConversableAgent(\n",
    "    \"code_executor_agent\",\n",
    "    llm_config=False,  # Turn off LLM for this agent.\n",
    "    code_execution_config={\"executor\": executor},  # Use the local command line code executor.\n",
    "    human_input_mode=\"ALWAYS\",  # Always take human input for this agent for safety.\n",
    ")\n",
    "\n",
    "# pip install -qqq matplotlib numpy\n",
    "message_with_code_block = \"\"\"\n",
    "Fist of all install libs by execute shell script:\n",
    "```sh\n",
    "pip install -qqq matplotlib numpy\n",
    "```\n",
    "Then use this is a message with code block.\n",
    "The code block is below:\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.random.randint(0, 100, 100)\n",
    "y = np.random.randint(0, 100, 100)\n",
    "plt.scatter(x, y)\n",
    "plt.savefig('scatter.png')\n",
    "print('Scatter plot saved to scatter.png')\n",
    "```\n",
    "This is the end of the message.\n",
    "\"\"\"\n",
    "\n",
    "# Generate a reply for the given code.\n",
    "reply = code_executor_agent.generate_reply(messages=[{\"role\": \"user\", \"content\": message_with_code_block}])\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(os.path.join(temp_dir.name, \"scatter.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_dir.name)\n",
    "temp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Conversation with code execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to store the code files.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Create a local command line code executor.\n",
    "executor = LocalCommandLineCodeExecutor(\n",
    "    timeout=10,  # Timeout for each code execution in seconds.\n",
    "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
    ")\n",
    "\n",
    "# Create an agent with code executor configuration.\n",
    "code_executor_agent = ConversableAgent(\n",
    "    \"code_executor_agent\",\n",
    "    llm_config=False,  # Turn off LLM for this agent.\n",
    "    code_execution_config={\"executor\": executor},  # Use the local command line code executor.\n",
    "    human_input_mode=\"ALWAYS\",  # Always take human input for this agent for safety.\n",
    ")\n",
    "\n",
    "# The code writer agent's system message is to instruct the LLM on how to use\n",
    "# the code executor in the code executor agent.\n",
    "\n",
    "code_writer_system_message = \"\"\"You are a helpful AI assistant.\n",
    "Solve tasks using your coding and language skills.\n",
    "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n",
    "1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n",
    "2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\n",
    "Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\n",
    "When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\n",
    "If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n",
    "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n",
    "Reply 'TERMINATE' in the end when everything is done.\n",
    "\"\"\"\n",
    "\n",
    "code_writer_agent = ConversableAgent(\n",
    "    \"code_writer_agent\",\n",
    "    system_message=code_writer_system_message,\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n",
    "    code_execution_config=False,  # Turn off code execution for this agent.\n",
    ")\n",
    "\n",
    "chat_result = code_executor_agent.initiate_chat(\n",
    "    code_writer_agent,\n",
    "    message=\"Write Python code to calculate the 14th Fibonacci number.\",\n",
    "    max_turns=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_executor_agent.clear_history()\n",
    "code_writer_agent.clear_history()\n",
    "\n",
    "chat_result = code_executor_agent.initiate_chat(\n",
    "    code_writer_agent,\n",
    "    message=\"Собери информацию о погоде в г.Екатеринбург за октябрь 2024 года. Для получения погоды используй сервис OpenWeather API_KEY = 40ae98eebd83853b790566269361b1e5 . Нарисуй график изменения температуры по дням. Сохрани график в файле weather.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(os.path.join(temp_dir.name, \"weather.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_dir.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Docker code executor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.coding import DockerCommandLineCodeExecutor\n",
    "from autogen import UserProxyAgent, AssistantAgent\n",
    "\n",
    "# Create a temporary directory to store the code files.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Create a Docker command line code executor.\n",
    "executor = DockerCommandLineCodeExecutor(\n",
    "    image=\"python:3.12-slim\",  # Execute code using the given docker image name.\n",
    "    timeout=10,  # Timeout for each code execution in seconds.\n",
    "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
    ")\n",
    "\n",
    "# Create an agent with code executor configuration that uses docker.\n",
    "code_executor_agent_using_docker = ConversableAgent(\n",
    "    \"code_executor_agent_docker\",\n",
    "    llm_config=False,  # Turn off LLM for this agent.\n",
    "    code_execution_config={\"executor\": executor},  # Use the docker command line code executor.\n",
    "    human_input_mode=\"ALWAYS\",  # Always take human input for this agent for safety.\n",
    ")\n",
    "\n",
    "# When the code executor is no longer used, stop it to release the resources.\n",
    "# executor.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_executor_agent_using_docker.clear_history()\n",
    "code_writer_agent.clear_history()\n",
    "\n",
    "chat_result = code_executor_agent_using_docker.initiate_chat(\n",
    "    code_writer_agent,\n",
    "    message=\"Собери информацию о погоде в г.Екатеринбург за октябрь 2024 года. Для получения погоды используй сервис OpenWeather API_KEY = 40ae98eebd83853b790566269361b1e5 . Нарисуй график изменения температуры по дням октябре 2024. Сохрани график в файле weather.png\",\n",
    ")\n",
    "executor.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Tools from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from autogen import register_function\n",
    "\n",
    "\n",
    "Operator = Literal[\"+\", \"-\", \"*\", \"/\"]\n",
    "\n",
    "\n",
    "def calculator(a: int, b: int, operator: Annotated[Operator, \"operator\"]) -> int:\n",
    "    if operator == \"+\":\n",
    "        return a + b\n",
    "    elif operator == \"-\":\n",
    "        return a - b\n",
    "    elif operator == \"*\":\n",
    "        return a * b\n",
    "    elif operator == \"/\":\n",
    "        return int(a / b)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid operator\")\n",
    "    \n",
    "\n",
    "# Let's first define the assistant agent that suggests tool calls.\n",
    "assistant = ConversableAgent(\n",
    "    name=\"Assistant\",\n",
    "    system_message=\"You are a helpful AI assistant. \"\n",
    "    \"You can help with simple calculations. \"\n",
    "    \"Return 'TERMINATE' when the task is done.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"], \"cache_seed\": None}]},\n",
    "    \n",
    ")\n",
    "\n",
    "# The user proxy agent is used for interacting with the assistant agent\n",
    "# and executes tool calls.\n",
    "user_proxy = ConversableAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=False,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Register the tool signature with the assistant agent.\n",
    "# assistant.register_for_llm(name=\"calculator\", description=\"A simple calculator\")(calculator)\n",
    "\n",
    "# # Register the tool function with the user proxy agent.\n",
    "# user_proxy.register_for_execution(name=\"calculator\")(calculator)\n",
    "\n",
    "\n",
    "\n",
    "# Register the calculator function to the two agents.\n",
    "register_function(\n",
    "    calculator,\n",
    "    caller=assistant,  # The assistant agent can suggest calls to the calculator.\n",
    "    executor=user_proxy,  # The user proxy agent can execute the calculator calls.\n",
    "    name=\"calculator\",  # By default, the function name is used as the tool name.\n",
    "    description=\"A simple calculator\",  # A description of the tool.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_result = user_proxy.initiate_chat(assistant, message=\"What is (1+5)*(10-8/2)?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant.llm_config[\"tools\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Tools from pydantic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Pydantic model\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    a: Annotated[int, Field(description=\"The first number.\")]\n",
    "    b: Annotated[int, Field(description=\"The second number.\")]\n",
    "    operator: Annotated[Operator, Field(description=\"The operator.\")]\n",
    "\n",
    "\n",
    "def calculator(input: Annotated[CalculatorInput, \"Input to the calculator.\"]) -> int:\n",
    "    if input.operator == \"+\":\n",
    "        return input.a + input.b\n",
    "    elif input.operator == \"-\":\n",
    "        return input.a - input.b\n",
    "    elif input.operator == \"*\":\n",
    "        return input.a * input.b\n",
    "    elif input.operator == \"/\":\n",
    "        return int(input.a / input.b)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid operator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_function(\n",
    "    calculator,\n",
    "    caller=assistant,  # The assistant agent can suggest calls to the calculator.\n",
    "    executor=user_proxy,  # The user proxy agent can execute the calculator calls.\n",
    "    name=\"calculator\",  # By default, the function name is used as the tool name.\n",
    "    description=\"'A calculator tool that accepts nested expression as input'\",  # A description of the tool.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant.llm_config[\"tools\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chat_result = user_proxy.initiate_chat(assistant, message=\"What is (1+5)*(10-8/2)?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_result.chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Two-agent chat**\n",
    "Наименьшая форма паттерна общения, при которой два агента общаются друг с другом.\n",
    "\n",
    "---\n",
    "\n",
    "**Sequential chat**\n",
    "Последовательность чатов между двумя агентами, соединенных механизмом переноса, который переносит резюме предыдущего чата в контекст следующего.\n",
    "\n",
    "---\n",
    "\n",
    "**Group Chat**\n",
    "Единый чат, в котором участвует более двух агентов. Важно понять, какой агент должен говорить следующим. Для поддержки различных сценариев мы предлагаем разные способы организации агентов в групповом чате:\n",
    "\n",
    "- **Стратегии выбора следующего агента**:\n",
    "  - **Равноценно** (round_robin)\n",
    "  - **Случайно** (random)\n",
    "  - **Вручную** (ручной выбор)\n",
    "  - **Автоматически** (auto) — по умолчанию, с использованием LLM для принятия решения.\n",
    "\n",
    "- **Ограничения на выбор следующего говорящего**:\n",
    "  Мы предоставляем способ ограничения выбора следующего говорящего.\n",
    "\n",
    "- **Пользовательская функция выбора следующего говорящего**:\n",
    "  Мы позволяем передавать функцию для настройки выбора следующего говорящего. С этой функцией вы можете построить модель StateFlow, которая позволяет реализацию детерминированного рабочего процесса среди ваших агентов.\n",
    "\n",
    "---\n",
    "\n",
    "**Neasted Chat:**\n",
    "Упаковывание рабочего процесса в одном агенте для повторного использования в более крупном рабочем процессе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Two agents chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/autogen_2.png\" width=600px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "student_agent = ConversableAgent(\n",
    "    name=\"Student_Agent\",\n",
    "    system_message=\"You are a student willing to learn.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ[\"OPENAI_API_KEY\"],  \"cache_seed\": None}]},\n",
    ")\n",
    "teacher_agent = ConversableAgent(\n",
    "    name=\"Teacher_Agent\",\n",
    "    system_message=\"You are a AI teacher.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n",
    ")\n",
    "\n",
    "chat_result = student_agent.initiate_chat(\n",
    "    teacher_agent,\n",
    "    message=\"Что такое агенты в языковых моделях?\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(chat_result.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(chat_result.cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Sequentional agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/autogen_sequence.png\" width=600px />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = ConversableAgent(\n",
    "    description='Покупатель товара. Заказывает товар из интернет-магазина.',\n",
    "    name=\"Customer_agent\",\n",
    "    system_message=\"Ты покупаешь товар в интернет магазине.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ[\"OPENAI_API_KEY\"],  \"cache_seed\": None}]},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Adder Agent adds 1 to each number it receives.\n",
    "sale_manager = ConversableAgent(\n",
    "    description='Менеджер по продажам интернет-магазина, принимает заказы от покупателей. Оплата при получении заказа.',\n",
    "    name=\"Sale_manager_agent\",\n",
    "    system_message=\"Ты уточняешь название товара, сообщаешь стоимость и запрашиваешь подтверждение покупки у покупателя\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n",
    "    # is_termination_msg=lambda msg: 'подтверждаю' in msg[\"content\"].lower(),\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Multiplier Agent multiplies each number it receives by 2.\n",
    "\n",
    "supplier = ConversableAgent(\n",
    "    description='Поставщик товара. Проверяет наличие товара на складе и при необходимости выполняет заказ товара у производителя',\n",
    "\n",
    "    name=\"Supplier_agent\",\n",
    "    system_message=\"Ты сообщаешь партномер и наличие товара на складе (товара нет, нужно заказывать у производителя).\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Subtracter Agent subtracts 1 from each number it receives.\n",
    "manufacturer = ConversableAgent(\n",
    "    description='Производитель товара. Производит товары по запросу и передает их в службу поставки',\n",
    "\n",
    "    name=\"Manufacturer_Agent\",\n",
    "    system_message=\"Ты производишь товар с указанным партномером и передаешь его в службу доставки\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "    \n",
    "deliver = ConversableAgent(\n",
    "    description='Служба доставки товара. Получает товар от производителя и доставляет товар покупателю.',\n",
    "\n",
    "    name=\"Deliver_agent\",\n",
    "    system_message=\"Ты доставляешь произведенный товар покупателю. Всегда сообщаещь номер транспортной накладной для отслеживания процесса доставки товара.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_results = customer.initiate_chats(\n",
    "    [\n",
    "        {\n",
    "            \"recipient\": sale_manager,\n",
    "            \"message\": \"Я хочу купить кроссовки Nike 40 размера\",\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "        {\n",
    "            \"sender\": sale_manager,\n",
    "            \"recipient\": supplier,\n",
    "            \"message\": \"Проверь наличие товара на складе и сообщи партномер\",\n",
    "            \"max_turns\": 1,\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": manufacturer,\n",
    "            \"sender\": supplier,\n",
    "            \"message\": \"Произведи данный товар и передай его в доставку\",\n",
    "            \"max_turns\": 1,\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": deliver,\n",
    "            \"sender\": manufacturer,\n",
    "            \"message\": \"Передай товар в службу доставки\",\n",
    "            \"max_turns\": 1,\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": customer,\n",
    "            \"sender\": deliver,\n",
    "            \"message\": \"Сообщи клиенту срок поставки товара\",\n",
    "            \"max_turns\": 1,\n",
    "            \"summary_method\": \"reflection_with_llm\",\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Group chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/autogen_group.png\" width=600px />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import GroupChat\n",
    "from autogen import GroupChatManager\n",
    "\n",
    "group_chat = GroupChat(\n",
    "    agents=[customer, sale_manager, supplier, manufacturer, deliver],\n",
    "    messages=[],\n",
    "    max_round=10,\n",
    "    # send_introductions=True\n",
    ")\n",
    "\n",
    "\n",
    "group_chat_manager = GroupChatManager(\n",
    "    groupchat=group_chat,\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCustomer_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Я хочу купить кроссовки Nike 40 размера\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Sale_manager_agent\n",
      "\u001b[0m\n",
      "\u001b[33mSale_manager_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Кроссовки Nike 40 размера стоят 7500 рублей. Вы подтверждаете покупку?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Customer_agent\n",
      "\u001b[0m\n",
      "\u001b[33mCustomer_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Да, я подтверждаю покупку кроссовок Nike 40 размера за 7500 рублей. Как я могу оформить заказ?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Sale_manager_agent\n",
      "\u001b[0m\n",
      "\u001b[33mSale_manager_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Отлично! Для оформления заказа мне понадобятся ваши контактные данные: имя, номер телефона и адрес доставки. Пожалуйста, предоставьте эту информацию.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Customer_agent\n",
      "\u001b[0m\n",
      "\u001b[33mCustomer_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Меня зовут Алексей, мой номер телефона 89001234567, адрес доставки: улица Ленина, дом 10, квартира 5, город Москва.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Supplier_agent\n",
      "\u001b[0m\n",
      "\u001b[33mSupplier_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "К сожалению, у нас нет кроссовок Nike 40 размера на складе, и их нужно заказывать у производителя. Если вы все равно хотите оформить заказ, я могу записать ваши данные и сделать запрос. Подтверждаете?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Customer_agent\n",
      "\u001b[0m\n",
      "\u001b[33mCustomer_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Да, я подтверждаю. Пожалуйста, запишите мои данные и сделайте запрос к производителю.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Manufacturer_Agent\n",
      "\u001b[0m\n",
      "\u001b[33mManufacturer_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Хорошо, я записываю ваши данные для заказа кроссовок Nike 40 размера:\n",
      "\n",
      "Имя: Алексей  \n",
      "Номер телефона: 89001234567  \n",
      "Адрес доставки: улица Ленина, дом 10, квартира 5, город Москва  \n",
      "\n",
      "Я сделаю запрос к производителю и сообщу вам, как только получу ответ. Спасибо за терпение!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Supplier_agent\n",
      "\u001b[0m\n",
      "\u001b[33mSupplier_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Запрос к производителю успешно отправлен. Как только я получу информацию о наличии кроссовок Nike 40 размера и сроках доставки, я сразу свяжусь с вами. Спасибо за ваше терпение!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Manufacturer_Agent\n",
      "\u001b[0m\n",
      "\u001b[33mManufacturer_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Пожалуйста! Я ожидаю обратной связи от производителя и сообщу вам, как только получу новости. Если у вас есть еще вопросы, не стесняйтесь спрашивать. Спасибо за ваш заказ!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = customer.initiate_chat(\n",
    "    group_chat_manager,\n",
    "    message=\"Я хочу купить кроссовки Nike 40 размера\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
